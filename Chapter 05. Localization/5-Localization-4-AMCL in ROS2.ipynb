{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f13214e",
   "metadata": {},
   "source": [
    "# 5.4 Trying AMCL in ROS2\n",
    "\n",
    "After the previous notebook, we are now quite knowledgeable about how Monte Carlo Localization works and all the ideas that underpin it. However, the implementation we worked with is, of course, kind of a simple one. More production-ready versions of the Monte Carlo Localization algorithm include a bunch of additional techniques that we sadly don't have time to explore in this course, such as *probabilistic beam-skipping*, *KD-Tree resampling*, or *degeneracy checks*.\n",
    "\n",
    "One such implementation, very widely used in real robotics applications, is **AMCL** (which stands for *Adaptive* Monte Carlo Localization). Despite some of the aforementioned bells and whistles, at its core, AMCL is essentially the same method we are already familiar with. But, how well does it work? Well, luckily for us, a version of AMCL is included in the `navigation2` package in ROS2, so we can quite easily test it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e471fb",
   "metadata": {},
   "source": [
    "### Setting up\n",
    "\n",
    "You will find the code you need for this test in the `robotics_ws` folder of this repository. This workspace includes the source code for several packages, which we will build. However, before we do that, we need to make sure we install all external dependencies. A nice thing about ROS is that it includes its own package manager, `rosdep`, to handle this sort of thing. From the root of the workspace, you can run:\n",
    "\n",
    "```\n",
    "sudo rosdep init\n",
    "rosdep update\n",
    "rosdep install --from-paths src\n",
    "```\n",
    "\n",
    "Let's also install `xterm`, to be able to dynamically open terminals for each process:\n",
    "```\n",
    "sudo apt install xterm\n",
    "```\n",
    "\n",
    "Once all the dependencies are installed, you can then build the local packages with\n",
    "\n",
    "```\n",
    "colcon build --symlink-install\n",
    "```\n",
    "\n",
    "Lastly, remember you need to set up the workspace for the active terminal session:\n",
    "\n",
    "```\n",
    "source install/setup.bash\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1bbb05",
   "metadata": {},
   "source": [
    "### Running the demo\n",
    "\n",
    "The included package `particle_filter_demo` has a prepared example to test AMCL. You can run it with\n",
    "\n",
    "```\n",
    "ros2 launch particle_filter_demo demo_warehouse.launch.py\n",
    "```\n",
    "\n",
    "This will open our trusty Rviz window to visualize what is going on, as well as an additional terminal emulator with the `keyboard_control` node. We are also launching `mvsim` to actually handle the simulation, but in `headless` mode (so, no GUI). The simulator might take a moment to start the first time you run the command, since it has to download some data to set up the scene.\n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"images/amcl.png\" width=\"800\" alt=\"\">\n",
    "  <figcaption>\n",
    "  </figcaption>\n",
    "</figure>\n",
    "\n",
    "In this visualization we will see the map of the simulated environment, the point cloud generated from a laser scanner, and the pose of the robot. Actually, we will see **two** poses for the robot: in <font color=\"blue\">blue</font>, the one estimated from pure odometry, and in <font color=\"green\">green</font> the one estimated by AMCL (along with its uncertainty).  \n",
    "\n",
    "The `keyboard_control` node just listens to your key presses and sends velocity commands to the robot as a response. You can use the arrow keys to change the linear and angular speeds of the robot, and the space bar to completely stop.\n",
    "\n",
    "Play around with the simulation, and see how well AMCL manages to localize the robot. You can judge the quality of the estimation by how well the point cloud generated from the sensor reading aligns with the map of the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1610bd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Changing parameters\n",
    "\n",
    "Most ROS2 nodes allow you to tune their behavior by changing their parameters. AMCL is no exception, and has quite a few we can play with. You can find these parameters inside a file: `robotics_ws/src/particle_filter_demo/resources/params.yaml`\n",
    "\n",
    "You are probably not going to be familiar with all of them. Some are very ROS-specific things (such as `TF` frames and topics), and some refer to the *extra refinements* (like beam-skipping) we were mentioning earlier. However, you will find some things that do sound familiar, such as minimum and maximum particle counts, or the `sigma_hit` parameter, which is the standard deviation of the gaussian used to generate the likelihood field.\n",
    "\n",
    "You can try messing about with these parameters, and maybe even with some of the ones you don't know, and see what happens!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d20a2f",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (1)</i></b></font>\n",
    "\n",
    "Let's stop playing for a moment, and **answer the following questions**:\n",
    "\n",
    "- As you know, `mvsim` is the process that manages the robot simulation. How do you think the `keyboard_control` node is controlling the speed of the robot? Can you think of some way to test this theory using `ros2` terminal commands?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "\n",
    "- What happens to the two estimated poses over time? Can you explain the difference in their evolution?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "\n",
    "- The uncertainty of the robot pose estimated by AMCL is shown by a magenta ellipse (for the position) and a yellow triangle (for the orientation). Can you observe any difference in this uncertainty when running the algorithm with different parameters?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
